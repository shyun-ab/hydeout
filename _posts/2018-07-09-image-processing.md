---

layout: post

title: "디지털영상처리 (Image Processing)"

categories:

  - Notes

commit: true

---


* 필기가 없는 부분은 ppt에 필기했음 (나중에 업데이트 예정)

## 1장. 영상처리의 개요

	• 영상처리의 분야
		○ 영상의 기하학적 변형: 다른 각도에서 찍은 사진은 배율이 다르다 -> view point가 맞도록 변형하여 이어붙임
		○ 영상의 화질 개선
		○ 영상의 복원: 오래된 과거의 영상들 복원 등
		○ 영상 데이터 압축: (디지털 영상 시기) 가능하면 화질을 떨어뜨리지 않고 압축할 수 있도록
		○ 객체 인식: 딥러닝 적용

	• Terminology
		○ Bitmap: 픽셀의 2차원 배열
		○ Aspect Ratio: 이미지의 가로/세로 크기 비
			§ Pixel Aspect Ratio: 픽셀 하나의 가로/세로 크기 비
		○ Half-tone printing: 검은색 하나로 회색조를 표현할 수 있게 해주는 기술

	• Graphics/Image Data Types
		○ 1-Bit images (monochrome image): 0은 색x 1은 색o (한가지 색)
		○ 8-Bit Gray-Level images: 밝기 정보만으로 구성 (0: black ~ 255: white 숫자가 클 수록 밝다!)                                하나의 픽셀이 1바이트(8bits)로 표현됨
		○ 24-Bit True Color images: 하나의 픽셀이 3바이트(RGB 각 1바이트 씩)로 표현                                 실질적으로 32bit로 저장됨(1바이트는 알파 채널(투명도를 나타냄) 값)                                 압축없이는 용량을 많이 차이함 (921.6 Kbytes)
		○ 8-Bit Color images: 24-bit true color 정보를 가지고 있는 팔레트(color lookup table)를 사용                         table의 인덱스만 사용하여 색을 표현



## 2장. Human Perception of Image

	• Iris(홍채): 홍채 인식 실패할 확률 100만분의 1?

	• Retina(망막)
		○ Cone(원추세포): R,G,B 3개의 type -> 색 인식.                     Fovea(중심축) 근처에 몰려 있음(시야 중앙에 위치),                      때문에 우리 시야에서 가운데 부분이 해상도가 높고 주변의 detail이 떨어짐
		○ Rod(간상세포): 망막 전역에 분포. 

	• Blind Spot 
		○ 그래프) 파선으로 나타낸 양이 Rod의 수 / 실선이 Cone의 수 -> 시야각 중 어디에 있는지 나타낸 그래프! 

	• 상은 거꾸로 맺히지만 뇌에서 인식할 때 똑바로 인식


	• Weber Ratio(Critical ratio): 중앙 부분에 밝기가 차이가 난다고 느끼면 손을 든다고 했을 때 50%의 사람들이 인식할 수 있는 감도의 차이 비
		○ 어두운 곳에서는 조금만 변화해도 sensitivity가 높아짐, 밝은 곳에서는 많이 변화해야 인식함
		○ 사람이 밝기를 인지할 때 절대적인 값만으로 이야기할 수 없다.
		
	• Mach band effect: 밝은 것 옆에서는 더 어두워 보이고, 어두운 것 옆에서는 더 밝아 보임 (실제 색 보다)

	• 착시현상: 사람의 뇌는 물체를 완성시키려는 특징이 있음. 물체를 파악할 때 주변의 영향을 받는다.


	• Digitization (Image Capturing): 아날로그 -> 디지털 process
		○ Analog: 연속적인 값을 가짐 / Digital: 불연속적
		
		○ Sampling(표본화): 빛이 반사되어 capturing device로 들어옴 -> 격자 하나가 빛의 세기 하나를 인식                        격자 하나의 크기가 커지면 dpi가 떨어짐 -> 해상도와 연결됨                        좌표 상의 digitization
			§ Nyquist theorm: 주파수의 2배(Nyquist Rate)만큼 읽어라(샘플링해라)
			§ Nyquist Frequency: 내가 샘플링한 횟수의 1/2만큼 신호를 복원할 수 있다
			§ Sampling Grid: 격자의 모양(꼭 사각형인 것은 아니다) ex) 원, 육각형 등
			
		○ Quantization(양자화): (ex) Cell 하나에 8비트 할당 -> 격자 하나는 256레벨의 빛 인식 가능                            크기 상의 digitization
			§ Uniform Q: 크기 구간을 똑같이 하는 것
			§ Non Uniform Q: Weber Ratio를 적용.. 크기 구간을 각각 다르게 함
			§ Vector Q: 벡터 공간을 만들어서 나눈 후 mapping…?? 비트 조합을 보고 rule을 찾아서…
			§ Monochrome(단색)의 경우 gray level
			§ Saturation: 더 높은 값이어야 하는데 표현되지 못하고 짤림(noise의 한 종류)
			Noise(양자화 과정의 노이즈): 실제값과 다르게 나타나는 부분
			
		○ 격자가 클 수록 딱딱한 edge(눈에 띔). 해상도가 높다 = 격자가 작다 or 많다

		○ Contrast(명조 대비)



## 3장. BMP 파일의 이해

	• 비트맵 개요
		○ 비트맵(bitmap): 점으로 영상을 표현
		○ 벡터 그래픽: 점, 선, 면을 표현할 수 있는 오브젝트
		=> 비트맵과 벡터의 차이는 확대를 하면 명확해짐!

	• BMP 파일의 이해
		○ Bitmap file header
		○ Bitmap info header
		○ RGBQUAD = 팔레트(color table): 트루컬러 비트맵에서는 존재x                                           B, G, R의 순서로 들어가있다는 것 주의!!                                           Gray scale에서는 (0,0,0,0), (1,1,1,0) ~ (255,255,255,0)
		○ 픽셀 데이터: 상하가 뒤집혀진 상태로 저장(아래 왼쪽부터 한줄씩 순서대로)
		○ 4바이트 단위로 저장 -> 패딩 Orow_size (ColorDepth = BitCount, PictureWidth = Width)

	• 실제 BMP 파일의 분석
		○ Little Endian
		○ 픽셀 데이터 순서(little endian 포함해서 써지는 순서 그대로!)

	• BMP 파일을 화면에 출력



## 4장. GIF Format

	• GIF (Graphics Interchange Format)
		○ LZW 알고리즘에 기반 (pixel data 영역을 압축하는 알고리즘)
		○ 8-bit color image (256개 색만 지원. True color (X)) -> 자연 영상이 아닌 컴퓨터 graphics와 같은 만들어낸 영상에 적합
		○ Interlacing 지원 = 건너뛰고 전송. 데이터를 절반만 받아도 대략적으로 이해 가능87년도에는 전송 속도가 매우 느리기 때문에 이런 모드가 필요했음<-> sequantial(progressive) display(위에서 한 줄씩 차례대로 display/전송)
		○ GIF89a 버전은 간단한 애니메이션 지원(delay time 등)

	• GIF87a (87년도에 released)
		○ GIF Signature: GIF format 알림 (text로 열면 맨 처음에 GIF87a라고 써있음)
		○ Screen descriptor(=/= image descriptor)
			§ GIF는 이미지를 띄울 공간을 먼저 설정함 (액자, 스크린과 같이)
			§ Cr : (cr+1)bits의 color resolution을 나타냄 (숫자가 높을 수록 색의 개수가 많다는 얘기)     cr이 7이라면 2^8개의 색이 있다는 말
		○ Global Color Map: 색의 개수만큼 index가 존재
		○ Image descriptor
			§ Sequantial order인지 interlacing인지 나타냄interlacing 순서: 8번 라인 채워줌 -> 4번 라인 -> 2번 -> 홀수 라인 (총 4passes)
		○ Local Color Map: 형식은 global과 동일
		○ Raster Area: BMP파일의 pixel data area와 비슷. 차이점은 true color가 아니기 때문에 RGB의 index 값을 가짐 -> 얘가 LZW 알고리즘으로 압축됨?

	• Color Lookup Tables (LUTs)
		○ RGB 순서로 3byte
		○ 24bit true color 정보가 있음
		○ 256개 color를 뽑는데 따로 알고리즘이 정해진 것은 아님(방법이 여러가지가 있음)ex)
			§ 표현하는 color를 모두 포함하는 가장 작은 3차원 box를 만듦
			§ 직육면체의 가장 긴 축을 기준으로 pixel 수가 반인 곳을 찾아 2개의 box로 나눔
			§ 나뉜 box에서 각각 또 가장 긴 축을 기준으로.. 계속 반복-> 언제까지? : 256개의 box가 나올 때까지 (8단계 (엄밀히 말하면 8번은 아님-각각의 box에 대해 시행해야 하기 때문))
			§ 256개의 box가 각각 하나의 색을 대표함 - 어떤 색이 가장 가까운가? 그 색의 index를 가지고 감mapping되는 색이 무조건 중간 값은 아니다.

	• GIF89: Extension block definitions을 이용 -> transparency와 delay 표현         GIF87 포맷으로도 나타낼 수는 있으나 바로 위(↑)의 내용을 이해하지 못함         Sorted Color Table: 많이 쓰는 color를 앞에 배치하면 LZW 알고리즘의 효율이 올라감


	• JPEG (Joint Photographic Experts Group)
		○ 사람이 영상을 어떻게 인지하느냐를 처음으로 고려

	• PNG (Portable Network Graphics)
		○ GIF 기반 확장판
		○ Interlacing 모드 존재 (7passes)

	• TIFF (Tagged Image File Format)
		○ 스캐너가 저장하는 포맷으로 많이 사용
		○ 원래 이미지 포맷이 무엇인지 별로 상관x -> 이 정보를 tag에 담고 추가 정보 O
		○ 무손실 포맷 (JPEG이 나오면서(?) 손실 포맷도 지원)

	• EXIF (Exchange Image File)
		○ 일본에서 만든 디지털 카메라를 위한 이미지 포맷
		○ Data는 JPEG으로 되어 있음 -> meta data를 붙여서 EXIF로 만듦(노출 시간, 조리개, 초점 거리, 렌즈 종류, 시간정보 등등 포함)(이런 것들을 부가적으로 포함하는 정보는 사실 EXIF이고 표면적으로만 JPEG이다?)



## 6장. 화질 향상 기법

	• 영상 반전: 영상 내의 모든 픽셀 값을 하나하나 반전시키는 것 (필름 카메라-네거티브)              (256 레벨 그레이스케일 가정)              밝기 정보 g(x,y)=255−f(x,y)

	• 밝기와 명암비 조절
		○ 밝기 조절: g(x,y)= f(x,y)+n              마지막에 오버플로우가 나지 않도록 255로 조정해주는 것 중요 (픽셀 값 범위 조정)
		○ 명암비 조절: 밝은 것은 조금 더 밝게, 어두운 것은 좀 더 어둡게                 밝기 측면에서 화질이 안 좋다고 느낄 때 가장 쉽고 확실한(?) 방법                 g(x,y)=f(x,y)+(f(x,y)−128)∗a                 a는 기울기 / 오버플로우 마찬가지 (픽셀 값 범위 조정)

	• 감마 보정: 모니터 등 장치에서 원본 영상의 밝기 값을 정확하게 표현하기 위함

	• 히스토그램 = 막대 그래프: 영상 내에서 각 그레이스케일 값에 해당하는 픽셀의 개수를 나타낸 것
		○ 정규화된 히스토그램: 각 픽셀 개수를 영상 전체 픽셀 개수로 나눠준 것 (=확률)
		○ 히스토그램이 왼쪽에 쏠려 있다 = 어두움, 오른쪽에 쏠려 있다 = 밝음가운데 몰려 있다 = 명암비가 작음골고루 퍼져 있다 = 명암비가 큼

	• 히스토그램 균등화: 히스토그램을 그레이스케일 전 구간에서 골고루 나타나도록 함
		○ 히스토그램 스트레칭: 한쪽이나 중앙으로 치우친 히스토그램 개선
			§ Constrast stretching: 왼쪽부터 최초로 나타나는 픽셀을 찾아서 그 픽셀의 명암만큼 전부 빼줌                            -> 왼쪽으로 다 붙게 됨 -> 다시 늘려줌                            (새로운 명암값) = 255 * (X-low) / (high-low)                            => 끝과 끝에 low와 high가 있으면 스트레칭 불가
			§ Ends-in search: low와 high 범위값을 지정해서 똑같이 stretching



## 7장. 영상의 산술 및 논리 연산

	• 영상의 산술 연산
		○ 덧셈 연산
		○ 뺄셈 연산
		○ 평균 연산
		○ 차이 연산: 주로 cctv같은 곳에서 많이 씀

	• 영상의 논리 연산
		○ AND 연산 (논리곱)
		○ OR 연산 (논리합)

	• 산술 및 논리 연산 기능 구현

	• 비트 평면 분할
		○ Ex) 픽셀 값이 128보다 크거나 같은 것들은 1, 아래의 것들은 0
		○ Ex) 64의 배수 값인 픽셀만 1, 나머지는 0
		○ => 비트맵은 비손실 압축이기 때문에 가능 / jpeg은 손실 압축이기 때문에 불가능



## 8장. 다양한 공간적 필터링 기법

	• 공간적 필터링
		○ 필터링: 영상에서 특정 주파수 성분을 제거
		○ 공간적 필터링(Spatial filtering): 영상에서 원하는 정보만을 걸러내는 기법
			§ Mask
				□ g = 출력영상 / m = 마스크 / f = 원 영상
				□ 마스크의 크기는 대부분 가로세로 홀수로 잡는다 => center가 생기기 때문
			§ 최외곽 픽셀 처리 방법 3가지
				1. 마스크 연산에서 제외
				2. 최외곽 픽셀 바깥에 가상의 픽셀이 있다고 가정
				3. 최외곽 픽셀이 반대쪽과 이어져 있다고 생각

	• 영상 부드럽게 만들기
		○ 평균 값 필터(Mean filter): 특정 좌표 값을 주변 픽셀들의 그레이스케일 값의 산술 평균 값으로 설정
		○ 가중 평균 값 필터(Weighted mean filter): 가운데 위치한 픽셀에 가중치를 더 줌
		○ 가우시안 함수

	• 영상 날카롭게 만들기
		○ 언샤프 마스크(Unsharp mask) 필터
		○ 라플라시안 필터: 영상의 2차 미분을 이용
		○ 하이부스트 필터

	• 잡음 생성
		○ 균일 분포
		○ 정상 분포
		○ 소금&후추 잡음: 0 또는 255의 잡음

	• 잡음 제거를 위한 비선형 필터
		○ 미디언(Median) 필터: 주변 픽셀 값을 정렬하여 중간값을 사용
		○ 경계선 보전 잡음 제거
			§ 비등방성 확산 필터: 내 사방 픽셀을 보면서 얼마나 변하는가(?)도 봄



## 9장. 영상의 기하학적 변환

	• 영상의 이동 변환: x와 y좌표를 변환 (x, y) -> (x+a, y+b)

	• 영상의 크기 변환: S가 0보다 크면 확대, 작으면 축소
	
		○ 확대
			§ 순방향 매핑 -> 확대 시 hall이 생긴다
			§ 역방향 매핑 -> x, y 값이 실수형으로 나옴
				□ 보간법: 주변 픽셀 값을 이용하여 결정 <확대할 때만 사용>
					® 최근방 이웃 보간법(Nearest neighbor interpolation): 가장 가까운 위치에 있는 값 참조 (반올림!)  빠르고 구현 쉬움, 계단 현상O
					® 양선형 보간법(Bilinear interpolation): 픽셀을 둘러싼 주변 네 개의 픽셀 값에 가중치를 곱한 값의 합  가장 단순, 실제로 많이 쓰는 보간법. 계단 현상은 줄어드나 smoothing  식 ppt 참조 - 이해하면 됨
					® 3차 회선 보간법(Cubic convolution interpolation): 가로로 4번 계산한 값을 가지고 세로로 1번 해서 계산  가중치 함수 따로 있음 (ppt-실선 파선 안 맞음 ㅠ)  엣지가 비교적 나타난다!
		○ 축소: 한 픽셀로 구성된 선분은 축소할 때 사라지는 경우 많음 -> 부드럽게 필터링한 후 축소

	• 영상의 회전 변환: 원점을 기준으로 회전하는 경우
	
		○ 특수 각(90, 180, 270도) 회전은 sin, cos 사용X (ppt에 식)

	• 영상의 대칭 변환
		○ 좌우 대칭: y값 그대로! 
		○ 상하 대칭: x값 그대로!



## 10장. 주파수 공간에서의 영상 처리

## 11장. 영상의 특징값 추출 방법

## 12장. 컬러 영상 처리

## 13장. 영상 분할

	• 이진화 기법
		○ 이진화: 영상의 픽셀 값을 0 또는 255 (배경 / 객체)로 만드는 작업          일반적으로 밝기 정보의 차이로 분리가 된다          색 정보 사용하는 예) 얼굴 인식(스킨톤 HSI or YCbCr)
		
			§ 전역적 이진화: 전체 픽셀에 대하여 하나의 임계값
			§ 지역적 이진화: 밝기 정보에 따라서 영상을 분할, 다른 임계값
			
			§ 이진화 임계값 설정 - 반복적 방법(iterative method): 임의로 임계값 T 결정 -> T보다 작은 픽셀 값들의 평균을 u1, 큰 값들의 평균 u2 -> T = (1/2)*(u1+u2) -> 변화 없을 때까지 반복


	• 레이블링 기법
		○ 레이블링(Labeling): 동일 객체에 속한 모든 픽셀에 고유한 번호를 매기는 작업                         (=이어져 있는 객체는 같은 객체이다, 한 덩어리이다 라고 보는 것)
		
		○ 전통적 레이블링: 4-이웃 연결성(4-neighbor connection)                      2번 스캔 - 첫번째: 레이블 전파 & 등가 테이블 만듦                                    두번째: 등가 테이블 참조 & 각 픽셀에 고유 레이블 부여
			§ 레이블 = 새로운 값이 나올 때마다 +1 해서 레이블 지정
			
				□ 첫 번째 스캔
					® 이미 방문한 픽셀에 레이블 존재X -> 배경 픽셀이라는 의미이다?
				□ 등가 테이블 정리 (resolve)
					® (5,4)가 있고 (4,2)가 있으면 (5,2)로 바꿔줌
				□ 두 번째 스캔
					® ex. (5,2)와 (4,2)를 모두 2로….바꿔줌
				
			§ ex) 쭉 스캔….. 두 이웃 픽셀 모두 레이블 X - 첫번째 값 나왔을 때 (1,1)
			§ 두 레이블 중 작은 번호(1)의 레이블을 지정하고 (? => 1)등가 테이블을 조정한다 ( (4,4) => (4,1) )
			
			§ 단점!! : 숫자 뛰어 넘음 (위에 예제 레이블 1 다음에 3)

		○ 전통적 레이블링 개선 - 등가 테이블 정리할 때 숫자 순서대로 개선 (위 예제 3 -> 2)                               *주의: 정리할 때 마지막에 하는 거고 헷갈려서 (2,1) (3,2)라고 3바꾸면 안됨


	• 외곽선 추적(Contour tracing = boundary tracing): 객체의 외곽선을 따라 이동                                                                 8 방향 연결성 (8-neighbor connection)
		○ 알고리즘
			§ 맨 첫번째 픽셀을 시작으로 외곽선 추적. 방향 d = 0
			§ 진행 방향에 픽셀 존재하면 그 픽셀로 이동, d = d-2존재하지 않으면 방향 d = d+1
			§ 현재 픽셀 위치가 시작 좌표와 같고 d = 0이 되면 추적 종료



## 14장. 모폴로지 연산

	• 이진 영상의 모폴로지 연산
		○ 모폴로지(Morphology) 연산
			§ 영상을 형태학적인 측면에서 다루는 기법
			§ 전처리(ex.변화하는 것을 방지하기 위해) or 후처리의 형태로 널리 사용
			§ 집합이론에 기반, 소문자 a = 특정 픽셀 / 대문자 A = 집합
			
		○ 구성 요소
			§ A = 입력 영상
			§ B = 연산의 결과를 조절
			§ 점 = 원점
			
		○ 침식(erosion) 연산
			§ B가 x만큼 이동한 집합이 A의 부분집합인 경우 x
				□ B가 A에 모두 포함되는 때의 원점 좌표의 집합!(원점 기준으로 움직여야 함)
				□ 객체 영역 픽셀이 점점 줄어든다
					
		○ 팽창(dilation) 연산
				□ 겹치는 게 있는 순간 그 때의 원점 좌표의 집합!!(원점 기준으로 움직여야 함)
				□ 객체 영역 픽셀이 점점 늘어남! 내부 구멍이 메워짐
		○ 침식 연산과 팽창 연산의 관계: 드모르간 법칙!
		○ 침식 후 팽창 or 팽창 후 침식: 왠만한 애들은 복구가 되지만 완벽히는 안된다~!
			§ 침식 후 팽창 = 열기(opening) 연산 -> 잡음 제거
			§ 팽창 후 침식 = 닫기(closing) 연산
			
		○ 외곽선 검출: (원본 영상) - (침식 연산 수행한 결과 영상)


	• 그레이스케일 영상의 모폴로지 연산
		○ 이진 영상의 모폴로지 연산 확장
		○ 구성 함수 (structuring function)
		○ 침식: 다 들어가기 전에는 0….. 다 들어가면 5씩 뺀다? 근데 미니멈을 취한다??????
			§ 밝은 값이 줄어듦
		○ 팽창: 맥시멈을 취한다??? 그림 잘못됐음
			§ 밝은 값이 늘어남



## 16장. 동영상 처리

	• AVI 파일 처리
		○ AVI(Audio Video Interleave) 파일
			§ 마이크로소프트사에서 만든 디지털 비디오 파일 포맷
			§ 일반적인 비디오 파일 - 오디오/비디오 파일을 잘개 쪼개서 사이사이에 끼운다..
			§ AVI 파일 - 압축되어 있는지 아닌지 상관하지 않고 쪼개서 끼움(?)압축된 비디오 포맷의 avi 파일은 압축 방법을 해제할 수 있는 코덱(codec) 필요

	• AVI 플레이어 만들기
		○ AVIFIle 함수는 윈도우즈에서 모두 제공!
		○ 이 부분 신경 안 쓴다?

	• 움직임 벡터 추정
		○ 동영상: 정지사진을 연속적으로 보여주는 것 (유럽 1초당 25장.. 우리나라 1초당 30장 등)-> 일반적으로 연속적일 때 배경 동일/움직임 크지 않음-> 이것을 이용해서 효율적으로(용량 면에서) 하기 위해 움직임 벡터 사용
		
		○ 움직임 벡터(motion vector)
			§ 영상의 시간 축 방향으로의 변화 감지. 동영상 내 객체의 움직임 정보를 추출
			§ 옵티컬 플로우
				□ 얼마나 변했는지 픽셀을 찾음
				□ 픽셀 단위로 계산하기 때문에 연산량이 많고 시간 오래 걸림
			§ 블록 매칭
				□ 이미지를 블록 단위로 잘게 쪼개서 유사한 부분이 어디에 있느냐를 찾음-> 그곳으로 이동했을 거라고 추정
				□ 교수님이 아시는 모든 비디오 포맷은 블록 매칭 사용 ㅎ (ex. MPEG 1, 2)
				□ 타겟 프레임의 타겟 블록이 이전 프레임의 어느 위치에서 이동한 블록인지 추정
				□ 오직 2차원 이동만 존재한다고 가정! (크기가 커지고 이런거 신경X)근데 사실 보통 객체보다 작은 크기로 블록을 쪼개기 때문에 상관없다
				□ W는 Search window (해당 블록 근처로 한정 - 갔으면 얼마나 갔겠어)옛날 코덱은 그렇고 새로 나오는 코덱은 window가 없다 다 찾음 프로세스 좋아져서
				□ X축에서 얼마, y축에서 얼마 움직였을 것이다!라고 추정한 것이 움직임 벡터블록 매칭에서는 움직임 추정
				
		○ 평균 절대값 차이
			§ 두 블록의 유사도 평가 척도
				□ 원래 블록 (k, l)에서 (x, y)만큼 떨어진 …. 블록의 .. 최소값..? ??
		○ 검색 방법
			§ 전역 검색: 주변 모든 변위에 대하여 MAD 계산 -> 시간 너무 오래 걸림
			§ 다이아몬드 검색
				□ LDSP (큰 다이아몬드 검색 패턴) - 간격 큼
				□ SDSP (작은 다이아몬드 검색 패턴) - 간격 작음
				□ LDSP 9개 위치에서 MAD 계산 -> 최소 MAD 값 찾음 -> 가운데면 SDSP-> 가운데가 아니면 최소값 위치를 가운데로 설정 -> LDSP (반복) -> 가운데면 SDSP
				□ 요즘처럼 window가 작지 않으면 별로 효율이 좋지 않음 
			§ 2차원 대수적 탐색
				□ 9개 search point를 잡는다는 점은 다이아몬드와 유사
				□ 가장자리와 블록 사이의 중간점을 point로 잡음 (가운데까지 9개)-> 다이아몬드처럼 반복 (point가 가운데와 1만 차이날 때까지)
			§ Hierarchical Search (Multi-resolution)
				□ 영상을 subsampling (가로세로 1/4 or 1/8 축소해서 작게 만듦)
				□ 틀은 그대로. 영상을 줄였다가 2배씩 확대해서 original로 갈 때까지 찾음



## 17장. JPEG 압축표준의 이해

	• JPEG: 국제 표준! 정지 영상 압축의 기본
	
	• JPEG 압축 방식
		○ 무손실 부호화 - 공간적 예측 방식
		○ 손실 부호화 - DCT(discrete cosine transform) 기반 방식
	
	• JPEG 부호화 과정 (부호화 블록도)
		1. 3개의 영상이 생긴다 (R,G,B or Y,Cb,Cr => 보통 RGB는 YCbCr로 변환해서 함)
		2. 전처리기 - Subsampling = 8x8 블락으로 쪼갬!사람 눈의 특징 이용, 색 영상을 똑같이 가져갈 필요 없다. 그래서 Cb, Cr 반으로 줄여버림(Cb, Cr의 가로세로를 1/2씩)보통 4 2 0 크로마 subsampling을 함JPEG 코딩할 때 Y-Cb-Cr 순서로 하는 게 아니라 Y 블락 4개, Cb 블락 1개, Cr 블락 1개 순으로 묶어서 한다 -> 이 묶은 것을 MCU라고 함 
		3. Level shift - 0~255의 값에서 128을 뺀다 (optional)
		4. FDCT = 주파수 공간으로 변환. 코사인 함수를 기저함수로 갖는 transform을 하겠다u = x축 방향, v = y축 방향
		5. 양자화 = Low frequency는 살려주고 high frequency는 날려버리자(사람은 Low frequency에서 나오면 잘 알고 High frequency에서 나오면 잘 모른다)내가 원하는 단계로 한정된 개수로만 나타내자 -> 양자화를 세게 한다 -> 단계 수가 적음Q(u,v)로 나눠서 반올림 -> 저주파에서는 단계 높게, 고주파에서는 단계 낮게Q(u,v) 칸 안의 값이 작다는 것이 단계가 많다는 것, 크다는 것이 단계가 적다는 것
		6. 값들의 sequence로 두어야 인코딩하기가 편함. 양자화한 값들은 2차원 배열-> 이것을 벡터화 하는 것이 지그-재그 스캔! = 저주파부터 시작해서 올라가는 방향이라서.고주파 부분에서 0이 많이 나오기 때문에 (큰 값으로 나눠서) 지그재그로 하면 효율 굿뒤쪽에 0이 몰리기 때문에 데이터 전부를 유지할 필요 X
		7. DC값과 AC값 나눔DC = 각 8x8 블록의 맨 앞의 값 / AC = 나머지 63개차분부호화 (허프만 부호화=많이 나오는 애는 비트 적게, 적게 나오는 애는 많이)(SSS, Value)
		AC 값은 run-length 부호화 (skip, value)뒤가 다 0이면 (0,0) = EOB(End of Block)
		Value -> SSS로 바꿈 -> Skip/SSS -> 이거에 대한 허프만 코드로 또 바꿈-> 최종 비트열 = 허브만코드+Value에 대한 코드ex) AC (0,6) -> value SSS = 3 -> 0/3 -> 100 -> 100110
		8.  Y 블락 4개, Cb 블락 1개, Cr 블락 1개 순으로

	
	• JPEG 복호화 과정
		○ Low frequency만 있으면 선명, high frequency만 남기면 흐린 영상



## 18장. Stereoscopic Imaging (양안식 3D)

	• Stereoscopic Imaging의 원리
		○ 거리(Depth)의 인식
			§ Stereopsis (양안시/입체시) -> 우리는 여기에 기반을 두고 이야기 할 것이다!
			§ Accommodation of the eye (원근조절)
			§ 거리를 인식할 때 이용하는 것들
				□ Subtended visual angle
				□ Linear perspective - 소실점까지의 선 등을 이용해서 거리를 인식한다
				□ Vertical position - Object가 위쪽에 있으면 멀고, 아래쪽에 있으면 가깝다고 생각
				□ Haze - 멀리 있는 것들은 뿌옇게 보임
				□ 가까운 패턴은 크고 선명하게, 멀리 있는 패턴은 작아지면서 detail이 사라짐(Vertical position + subtended visual angle)
		○ 양안시차: 두 눈의 위치 차이(약 6.5cm)로 인하여 발생하는 각 눈에 입력되는 영상의 차이
	
	• Stereoscopic Imaging 기법들
		○ Stereoscopic Image
			§ 입체감을 위해 좌안과 우안에 입력되는 영상이 조금씩 다르도록 함
			§ 일반적으로 두 장의 영상을 사용
		○ Stereoscopic 영상의 취득
			§ Stereoscopic Camera - 좌안용 영상과 우안용 영상 따로 취득

	• Stereoscopic 3D
		○ 3D 디스플레이 방식
			§ Side-by-Side 방식: 이미지를 왼쪽 오른쪽 아예 따로 줌
			§ 안경방식 디스플레이
				□ 적청안경방식 (Anaglyph 3D)
					® 다른 색을 가진 필터(일반적으로 보색관계 적/청)를 이용
						◊ 왼쪽 - 청/녹색 제거 - 적색 필터 (적색 성분 구분 X)
						◊ 오른쪽 - 적색 제거 - 청/녹색 필터 (청/녹색 성분 구분 X)
					® 두 개가 뇌에서 합쳐지면서 하나의 영상으로 보인다
					® 안경쓰고 고개 돌리면 안 맞음..
				□ 편광안경방식 (Polarizer - 패시브글라스)
					® 원래 빛은 사방으로 진동..
					® 편광방식으로 한 쪽 방향으로 진동하는 빛만 들어오게 됨
					® 왼쪽과 오른쪽 눈을 90도 다르게 함
					® LG전자 TV - 눈이 반반만 보기 때문에 화질이 비교적 떨어짐CGV에서 나눠주는 3D 안경도 이런 방식
					® 회전 방향에 따라 맞추는 거기 때문에 고개 돌려도 맞음 ㅎ
				□ 셔터안경방식 (액티브글라스)
					® 안경이 왼쪽 눈과 오른쪽 눈을 번갈아가면서 가림..? (TV와 동기화)
					® 삼성전자 TV - 눈이 모든 화면을 다 보기 때문에 화질이 비교적 높다..고 하는데 안경이 개 비쌈.. 실용성이 떨어짐
		○ 기타 3D 관련 기술
			§ Depth Map
				□ 3D 영상을 인코딩할 때 왼쪽 오른쪽을 두 개 따로 저장할 수 도 있고,두 영상의 차이만 저장하기도 함, 또는 두 영상의 "Depth 정보"를 저장
				□ Depth 정보
					® 그레이 스케일
					® 가까운 곳은 밝게, 먼 곳은 어둡게



## 19장. 동영상 압축 I

## 20장. 동영상 압축 II

<br><br>